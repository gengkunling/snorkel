{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# TO USE A DATABASE OTHER THAN SQLITE, USE THIS LINE\n",
    "# Note that this is necessary for parallel execution amongst other things...\n",
    "# os.environ['SNORKELDB'] = 'postgres:///snorkel-intro'\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    }
   ],
   "source": [
    "# Parse the document and save into the sqlite server\n",
    "# see the intro-turtorial 1\n",
    "\n",
    "# Configure a doc pre-processer\n",
    "from snorkel.parser import TextDocPreprocessor\n",
    "doc_preprocessor = TextDocPreprocessor('data/test/')\n",
    "print doc_preprocessor.path\n",
    "\n",
    "\n",
    "# Running a Sapcy corpus parser\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "# spacy lang_model = en_core_web_md\n",
    "corpus_parser = CorpusParser(parser=Spacy()) # use spacy parser, fast but not accurate enough for NER\n",
    "\n",
    "\n",
    "\n",
    "#corpus_parser = CorpusParser() # use corenlp parser, slow but accurate for NER\n",
    "corpus_parser.apply(doc_preprocessor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Check if the document has beed loaded\n",
    "from snorkel.models import Document, Sentence\n",
    "for doc in session.query(Document).all():\n",
    "    print doc.id\n",
    "    #print doc.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Candidate Type\n",
    "from snorkel.models import candidate_subclass, Document, Candidate\n",
    "rel_spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "\n",
    "# Write the candidate extractor\n",
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import PersonMatcher\n",
    "ngrams         = Ngrams(n_max=7)\n",
    "person_matcher = PersonMatcher()\n",
    "cand_extractor = CandidateExtractor(rel_spouse, [ngrams, ngrams], [person_matcher, person_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "15\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, dev and test \n",
    "from snorkel.models import Document\n",
    "\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents   = set()\n",
    "test_sents  = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if i % 3 == 1:\n",
    "            dev_sents.add(s)\n",
    "        elif i % 3 == 2:\n",
    "            test_sents.add(s)\n",
    "        else:\n",
    "            train_sents.add(s)\n",
    "            \n",
    "print len(train_sents)\n",
    "print len(test_sents)\n",
    "print len(dev_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 3)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 17)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 1)\n"
     ]
    }
   ],
   "source": [
    "# Apply candidate extractors on all the sentences\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    cand_extractor.apply(sents, split=i)\n",
    "    print(\"Number of candidates:\", session.query(rel_spouse).filter(rel_spouse.split == i).count())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "for document in docs:\n",
    "    sent_offsets = [sent.abs_char_offsets[0] for sent in document.sentences]\n",
    "    char_offsets = [sent.char_offsets[0] for sent in document.sentences]\n",
    "    print char_offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "family = family | {f + '-in-law' for f in family}\n",
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(' ')\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "def LF_husband_wife(c):\n",
    "    return 1 if len(spouses.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_husband_wife_left_window(c):\n",
    "    if len(spouses.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "        return 1\n",
    "    elif len(spouses.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_same_last_name(c):\n",
    "    p1_last_name = last_name(c.person1.get_span())\n",
    "    p2_last_name = last_name(c.person2.get_span())\n",
    "    if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "        if c.person1.get_span() != c.person2.get_span():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def LF_no_spouse_in_sentence(c):\n",
    "    return -1 if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else 0\n",
    "\n",
    "def LF_and_married(c):\n",
    "    return 1 if 'and' in get_between_tokens(c) and 'married' in get_right_tokens(c) else 0\n",
    "    \n",
    "def LF_familial_relationship(c):\n",
    "    return -1 if len(family.intersection(get_between_tokens(c))) > 0 else 0\n",
    "\n",
    "def LF_family_left_window(c):\n",
    "    if len(family.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "        return -1\n",
    "    elif len(family.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_other_relationship(c):\n",
    "    return -1 if len(other.intersection(get_between_tokens(c))) > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number labeled:', 2)\n",
      "Sentence(Document 1,0,Top Nigerian comedian Julius Agwu with his wife Ibiere held a birthday party for their daughter Zahra who turned six recently   The party was held at Monkey Joes in Houston Texas yesterday September 7)\n",
      "\n",
      "Sentence(Document 1,0,Top Nigerian comedian Julius Agwu with his wife Ibiere held a birthday party for their daughter Zahra who turned six recently   The party was held at Monkey Joes in Houston Texas yesterday September 7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the first labeling function: LF_between_and\n",
    "labeled = []\n",
    "for c in session.query(rel_spouse).filter(rel_spouse.split == 0).all():\n",
    "    if LF_husband_wife(c) != 0:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))\n",
    "for i in range(len(labeled)):\n",
    "    print labeled[i].get_parent()\n",
    "    #print labeled[i].labels\n",
    "    print\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "    LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "    LF_family_left_window, LF_other_relationship\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Spouse(Span(\"Ibiere\", sentence=4, chars=[48,53], words=[8,8]), Span(\"Zahra\", sentence=4, chars=[96,100], words=[16,16]))\n",
      "[Label (LF_husband_wife_left_window = 1), Label (LF_familial_relationship = -1), Label (LF_family_left_window = -1)]\n",
      "Spouse(Span(\"Julius Agwu\", sentence=4, chars=[22,32], words=[3,4]), Span(\"Zahra\", sentence=4, chars=[96,100], words=[16,16]))\n",
      "[Label (LF_husband_wife = 1), Label (LF_familial_relationship = -1), Label (LF_family_left_window = -1)]\n",
      "Spouse(Span(\"Julius Agwu\", sentence=4, chars=[22,32], words=[3,4]), Span(\"Ibiere\", sentence=4, chars=[48,53], words=[8,8]))\n",
      "[Label (LF_husband_wife = 1), Label (LF_husband_wife_left_window = 1)]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching BRAT server at http://localhost:8001 [pid=79957]...\n",
      "Killing BRAT server [79943]...\n",
      "Removed existing collection at 'geng_spouse/train'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='http://localhost:8001/index.xhtml#/geng_spouse/train/' target='_blank'>Launch BRAT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch Brat\n",
    "from snorkel.contrib.brat import BratAnnotator\n",
    "\n",
    "brat = BratAnnotator(session, rel_spouse, encoding='utf-8', annotator_name='brat')\n",
    "\n",
    "# Initilize the brat program\n",
    "# the brat would copy the training data (split = 0) frrom the sqlite server \n",
    "# to the folder \"snorkel/snorkel/snorkel/contrib/brat/brat-v1.3_Crunchy_Frog/data/contract/train\"\n",
    "brat.init_collection(\"geng_spouse/train\", split=0, overwrite=True)\n",
    "\n",
    "brat.view(\"geng_spouse/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spouse(Span(\"Ibiere\", sentence=4, chars=[48,53], words=[8,8]), Span(\"Zahra\", sentence=4, chars=[96,100], words=[16,16]))\n",
      "[Label (LF_husband_wife_left_window = 1), Label (LF_familial_relationship = -1), Label (LF_family_left_window = -1)]\n",
      "-------------\n",
      "Spouse(Span(\"Julius Agwu\", sentence=4, chars=[22,32], words=[3,4]), Span(\"Zahra\", sentence=4, chars=[96,100], words=[16,16]))\n",
      "[Label (LF_husband_wife = 1), Label (LF_familial_relationship = -1), Label (LF_family_left_window = -1)]\n",
      "-------------\n",
      "Spouse(Span(\"Julius Agwu\", sentence=4, chars=[22,32], words=[3,4]), Span(\"Ibiere\", sentence=4, chars=[48,53], words=[8,8]))\n",
      "[Label (LF_husband_wife = 1), Label (LF_husband_wife_left_window = 1)]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#load all the candidates and labeling results from the server\n",
    "# the candiates are labeled \n",
    "train_cands = session.query(rel_spouse).filter(rel_spouse.split == 0).order_by(rel_spouse.id).all()\n",
    "for c in train_cands:\n",
    "    print c\n",
    "    print c.labels\n",
    "    print '-------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapped 1/1 (100%) of BRAT labels to candidates\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Spouse(Span(\"Ibiere\", sentence=4, chars=[48,53], words=[8,8]), Span(\"Zahra\", sentence=4, chars=[96,100], words=[16,16]))\n",
      "[Label (LF_husband_wife_left_window = 1), Label (LF_familial_relationship = -1), Label (LF_family_left_window = -1)]\n",
      "Spouse(Span(\"Julius Agwu\", sentence=4, chars=[22,32], words=[3,4]), Span(\"Zahra\", sentence=4, chars=[96,100], words=[16,16]))\n",
      "[Label (LF_husband_wife = 1), Label (LF_familial_relationship = -1), Label (LF_family_left_window = -1)]\n",
      "Spouse(Span(\"Julius Agwu\", sentence=4, chars=[22,32], words=[3,4]), Span(\"Ibiere\", sentence=4, chars=[48,53], words=[8,8]))\n",
      "[Label (LF_husband_wife = 1), Label (LF_husband_wife_left_window = 1)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_husband_wife</th>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_husband_wife_left_window</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_same_last_name</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_no_spouse_in_sentence</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_and_married</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_familial_relationship</th>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_family_left_window</th>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_relationship</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             j  Coverage  Overlaps  Conflicts\n",
       "LF_husband_wife              0  0.666667  0.666667   0.333333\n",
       "LF_husband_wife_left_window  1  0.666667  0.666667   0.333333\n",
       "LF_same_last_name            2  0.000000  0.000000   0.000000\n",
       "LF_no_spouse_in_sentence     3  0.000000  0.000000   0.000000\n",
       "LF_and_married               4  0.000000  0.000000   0.000000\n",
       "LF_familial_relationship     5  0.666667  0.666667   0.666667\n",
       "LF_family_left_window        6  0.666667  0.666667   0.666667\n",
       "LF_other_relationship        7  0.000000  0.000000   0.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the labelling functions\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "import numpy as np\n",
    "labeler = LabelAnnotator(lfs=LFs)\n",
    "\n",
    "np.random.seed(1701)\n",
    "L_train = labeler.apply(split=0)\n",
    "# L_train is essentially the sparse matrix\n",
    "# check the labeling results\n",
    "\n",
    "for i in range(3):\n",
    "    print L_train.get_candidate(session, i)\n",
    "    print L_train.get_candidate(session, i).labels\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (2, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "# Mapping BRAT Annotations to Snorkel Candidates and compare the accury of our labled train_cands\n",
    "# Import a collection of BRAT annotations,  map it onto the provided set\n",
    "# of candidates, and create gold labels. This method DOES NOT create new\n",
    "# candidates, so some labels may not import if a corresponding candidate\n",
    "# cannot be found.\n",
    "\n",
    "\n",
    "brat.import_gold_labels(session, \"geng_spouse/train\", train_cands)\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_train = load_gold_labels(session, annotator_name='brat', split=0)\n",
    "print L_gold_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "# Fit the generative model\n",
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=1000, decay=0.95, step_size=0.01 / L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 1.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 1 | FP: 0 | TN: 2 | FN: 0\n",
      "========================================\n",
      "\n",
      "[ 0.08316157  0.08057584  0.96242559]\n"
     ]
    }
   ],
   "source": [
    "# error analysis of the generative model\n",
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_train, L_gold_train)\n",
    "\n",
    "# generate the noisy-aware lables (marginals) for the training data\n",
    "train_marginals = gen_model.marginals(L_train)\n",
    "print train_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826128</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.821563</td>\n",
       "      <td>0.617129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.839635</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.839171</td>\n",
       "      <td>0.606398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.839749</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.830454</td>\n",
       "      <td>0.622798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.836043</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.835214</td>\n",
       "      <td>0.599312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.838271</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.835980</td>\n",
       "      <td>0.618141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.877854</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.879250</td>\n",
       "      <td>0.664912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.891821</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.891489</td>\n",
       "      <td>0.678680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.833969</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.832508</td>\n",
       "      <td>0.612877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.826128    0.7356   0.821563  0.617129\n",
       "1  0.839635    0.7352   0.839171  0.606398\n",
       "2  0.839749    0.7326   0.830454  0.622798\n",
       "3  0.836043    0.7258   0.835214  0.599312\n",
       "4  0.838271    0.7358   0.835980  0.618141\n",
       "5  0.877854    0.7532   0.879250  0.664912\n",
       "6  0.891821    0.7580   0.891489  0.678680\n",
       "7  0.833969    0.7342   0.832508  0.612877"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the coverage of the generative model for the LFs\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Spouse(Span(\"James Spader\", sentence=9, chars=[34,45], words=[7,8]), Span(\"Reed Birney\", sentence=9, chars=[215,225], words=[44,45]))\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Spouse(Span(\"James Spader\", sentence=9, chars=[34,45], words=[7,8]), Span(\"Tom Connolly\", sentence=9, chars=[201,212], words=[41,42]))\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Spouse(Span(\"James Spader\", sentence=9, chars=[34,45], words=[7,8]), Span(\"Liz\", sentence=9, chars=[155,157], words=[34,34]))\n",
      "[]\n",
      "0.5\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Spouse(Span(\"Tom Connolly\", sentence=9, chars=[201,212], words=[41,42]), Span(\"Reed Birney\", sentence=9, chars=[215,225], words=[44,45]))\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Spouse(Span(\"Liz\", sentence=9, chars=[155,157], words=[34,34]), Span(\"Reed Birney\", sentence=9, chars=[215,225], words=[44,45]))\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Spouse(Span(\"Liz\", sentence=9, chars=[155,157], words=[34,34]), Span(\"Tom Connolly\", sentence=9, chars=[201,212], words=[41,42]))\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "\n",
      "Sentence(Document 2,11,\"The Blacklist\" executive producer John Eisendrath says that the physical transformation in Liz will mirror a psychological one.   \")\n",
      "Spouse(Span(\"John Eisendrath\", sentence=16, chars=[35,49], words=[6,7]), Span(\"Liz\", sentence=16, chars=[92,94], words=[14,14]))\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "\n",
      "Sentence(Document 2,1,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Spouse(Span(\"James Spader\", sentence=6, chars=[34,45], words=[7,8]), Span(\"Reed Birney\", sentence=6, chars=[215,225], words=[46,47]))\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "\n",
      "[ 0.16833573  0.16833573  0.5         0.16833573  0.16833573  0.16833573\n",
      "  0.16833573  0.16833573  0.16833573  0.5         0.5         0.16833573\n",
      "  0.16833573  0.16833573  0.16833573  0.5         0.5       ]\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)\n",
    "# output marginals of the generative model\n",
    "# It should be noted that the generative model depends on\n",
    "# the LFs and operates on the output of labeler\n",
    "\n",
    "dev_marginals = gen_model.marginals(L_dev) \n",
    "for i in range(8):\n",
    "    print L_dev.get_candidate(session, i).get_parent() # sentence\n",
    "    print L_dev.get_candidate(session, i) # candidate\n",
    "    print L_dev.get_candidate(session, i).labels # labels by LFs\n",
    "    print dev_marginals[i] # labels by generative models\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error! Collection at 'geng_spouse/dev' already exists. Please set overwrite=True to erase all existing annotations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='http://localhost:8001/index.xhtml#/geng_spouse/dev/' target='_blank'>Launch BRAT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error! Collection at 'geng_spouse/test' already exists. Please set overwrite=True to erase all existing annotations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='http://localhost:8001/index.xhtml#/geng_spouse/test/' target='_blank'>Launch BRAT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finish the labeling of dev and test data\n",
    "brat.init_collection(\"geng_spouse/dev\", split=1, overwrite=False)\n",
    "brat.view(\"geng_spouse/dev\")\n",
    "\n",
    "brat.init_collection(\"geng_spouse/test\", split=2, overwrite=False)\n",
    "brat.view(\"geng_spouse/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (16, 0)\t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapped 1/1 (100%) of BRAT labels to candidates\n"
     ]
    }
   ],
   "source": [
    "# load up the gold labels for dev data\n",
    "dev_cands = session.query(rel_spouse).filter(rel_spouse.split == 1).order_by(rel_spouse.id).all()\n",
    "brat.import_gold_labels(session, \"geng_spouse/dev\", dev_cands)\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='brat', split=1)\n",
    "print L_gold_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-909cd84b0e67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load up the gold labels for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_cands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_spouse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_spouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_spouse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbrat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_gold_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"geng_spouse/test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mL_gold_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_gold_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'brat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mL_gold_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kunling/Dropbox/decisionengines/snorkel/snorkel/contrib/brat/brat.pyc\u001b[0m in \u001b[0;36mimport_gold_labels\u001b[0;34m(self, session, annotation_dir, candidates, symmetric_relations, annotator_name)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \"\"\"\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mmapped_cands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymmetric_relations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapped_cands\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kunling/Dropbox/decisionengines/snorkel/snorkel/contrib/brat/brat.pyc\u001b[0m in \u001b[0;36mmap_annotations\u001b[0;34m(self, session, annotation_dir, candidates, symmetric_relations)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_cands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_cands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_cands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m>>\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Mapped {}/{} ({:2.0f}%) of BRAT labels to candidates\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapped_cands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# load up the gold labels for test data\n",
    "test_cands = session.query(rel_spouse).filter(rel_spouse.split == 2).order_by(rel_spouse.id).all()\n",
    "brat.import_gold_labels(session, \"geng_spouse/test\", test_cands)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='brat', split=2)\n",
    "print L_gold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRNN] Training model\n",
      "[reRNN] n_train=3  #epochs=10  batch size=3\n",
      "[reRNN] Epoch 0 (0.25s)\tAverage loss=0.690271\tDev F1=0.00\n",
      "[reRNN] Epoch 1 (0.42s)\tAverage loss=0.665733\tDev F1=0.00\n",
      "[reRNN] Epoch 2 (0.55s)\tAverage loss=0.689899\tDev F1=0.00\n",
      "[reRNN] Epoch 3 (0.67s)\tAverage loss=0.661771\tDev F1=0.00\n",
      "[reRNN] Epoch 4 (0.80s)\tAverage loss=0.662512\tDev F1=0.00\n",
      "[reRNN] Epoch 5 (0.93s)\tAverage loss=0.664333\tDev F1=0.00\n",
      "[reRNN] Epoch 6 (1.06s)\tAverage loss=0.664365\tDev F1=0.00\n",
      "[reRNN] Epoch 7 (1.19s)\tAverage loss=0.662932\tDev F1=0.00\n",
      "[reRNN] Epoch 8 (1.39s)\tAverage loss=0.660743\tDev F1=0.00\n",
      "[reRNN] Epoch 9 (1.54s)\tAverage loss=0.658482\tDev F1=0.00\n",
      "[reRNN] Training done (1.55s)\n"
     ]
    }
   ],
   "source": [
    "# Training an LSTM model\n",
    "from snorkel.learning.disc_models.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        50,\n",
    "    'n_epochs':   10,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1,\n",
    "    'max_sentence_length': 100\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.000, Recall: 0.000, F1 Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "# The accuracy of the lstm for the dev data\n",
    "p, r, f1 = lstm.score(dev_cands, L_gold_dev)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "James Spader   Reed Birney\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "0.424342\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "James Spader   Tom Connolly\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "0.418509\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "James Spader   Liz\n",
      "[]\n",
      "0.5\n",
      "0.422157\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Tom Connolly   Reed Birney\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "0.41856\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Liz   Reed Birney\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "0.420706\n",
      "\n",
      "Sentence(Document 2,4,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "Liz   Tom Connolly\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "0.414858\n",
      "\n",
      "Sentence(Document 2,11,\"The Blacklist\" executive producer John Eisendrath says that the physical transformation in Liz will mirror a psychological one.   \")\n",
      "John Eisendrath   Liz\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "0.42259\n",
      "\n",
      "Sentence(Document 2,1,The FBI agent and Red Reddington (James Spader) will be on the run in Season 3 of the NBC series after the pair's Season 2 clash with the Cabal ended with Liz killing the corrupt U.S. Attorney General Tom Connolly (Reed Birney).\n",
      ")\n",
      "James Spader   Reed Birney\n",
      "[Label (LF_no_spouse_in_sentence = -1)]\n",
      "0.168335729296\n",
      "0.425395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_marginals = lstm.marginals(dev_cands)\n",
    "for i in range(8):\n",
    "    print L_dev.get_candidate(session, i).get_parent() # sentence\n",
    "    print L_dev.get_candidate(session, i).person1.get_span(), \" \", L_dev.get_candidate(session, i).person2.get_span() # candidate\n",
    "    print L_dev.get_candidate(session, i).labels # labels by LFs\n",
    "    print dev_marginals[i] # labels by generative models\n",
    "    print lstm_marginals[i]\n",
    "    print \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
