{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "snorkel_dir = '/Users/kunling/Dropbox/decisionengines/snorkel/'\n",
    "#snorkel_dir = '/Users/kunling/Dropbox/decisionengines/snorkel/treedlib'\n",
    "os.environ['SNORKELHOME'] = '/Users/kunling/Dropbox/decisionengines/snorkel/'\n",
    "sys.path.insert(0,snorkel_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlalchemy.orm.session.Session object at 0x10e456c10>\n",
      "<sqlalchemy.engine.base.Connection object at 0x10cc16dd0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "print session\n",
    "print session.connection()\n",
    "from sqlalchemy import MetaData\n",
    "import contextlib\n",
    "meta = MetaData()\n",
    "\n",
    "with contextlib.closing(session.connection()) as con:\n",
    "    trans = con.begin()\n",
    "    for table in reversed(meta.sorted_tables):\n",
    "        con.execute(table.delete())\n",
    "    trans.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not kill CoreNLP server [42975] [Errno 3] No such process\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# TO USE A DATABASE OTHER THAN SQLITE, USE THIS LINE\n",
    "# Note that this is necessary for parallel execution amongst other things...\n",
    "# os.environ['SNORKELDB'] = 'postgres:///snorkel-intro'\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Running a Sapcy corpus parser\n",
    "from snorkel.parser.spacy_parser import Spacy\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "corpus_parser = CorpusParser() # use corenlp parser, slow but accurate for NER\n",
    "\n",
    "\n",
    "# spacy lang_model = en_core_web_md\n",
    "#en_depent_web_md\n",
    "\n",
    "#corpus_parser = CorpusParser(parser=Spacy(lang='en_core_web_sm')) # use spacy parser, fast but not accurate enough for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/samples\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "parts: abs_sent_offset [0, 4, 12, 17, 21, 27, 32, 38, 46, 49, 54, 64, 67, 73, 77, 84, 87, 92, 94, 97, 101, 113, 122, 126, 130, 139, 141, 143, 145, 149, 158, 161, 165, 169, 174, 179, 182, 184]\n",
      "abs_sent_offset 0\n",
      "abs_sent_offset_end 185\n",
      "parts: abs_sent_offset [188, 193, 205, 216, 226, 227, 228, 237, 238, 240, 243, 248, 252, 260, 265, 268, 272, 279, 281, 287, 294, 295, 296, 306, 307, 309, 313, 323, 328, 329, 330, 336, 337, 338]\n",
      "abs_sent_offset 188\n",
      "abs_sent_offset_end 339\n",
      "parts: abs_sent_offset [339, 344, 353, 357, 362, 372, 375, 383, 388, 394, 398, 400, 405, 408, 412, 414, 417, 421, 429, 436, 440, 441, 453, 458, 459, 461, 466, 477, 479, 481, 490, 494, 496, 499, 504, 506, 510, 516, 523, 525, 530, 531, 543, 550, 551, 553, 558, 560, 564, 566, 568, 572, 576, 578, 581, 586, 588, 591, 593, 597, 602, 605, 607]\n",
      "abs_sent_offset 339\n",
      "abs_sent_offset_end 608\n",
      "parts: abs_sent_offset [0, 5, 14, 18, 23, 33, 36, 44, 49, 55, 60, 63, 66, 70, 73, 76, 80, 88, 98, 110, 111, 123, 128, 129, 131, 135, 141, 147, 153, 155, 164, 166, 174, 176, 181, 183, 187, 193, 200, 202, 207, 208, 220, 227, 228, 230, 235, 244, 246, 248, 252, 256, 258, 261, 271, 273, 276, 278, 282, 287, 290, 292]\n",
      "abs_sent_offset 0\n",
      "abs_sent_offset_end 293\n",
      "parts: abs_sent_offset [295, 299, 306, 309, 315, 318, 322, 330, 339, 345, 349, 356, 364, 371]\n",
      "abs_sent_offset 295\n",
      "abs_sent_offset_end 372\n",
      "parts: abs_sent_offset [373, 378, 381, 385, 395]\n",
      "abs_sent_offset 373\n",
      "abs_sent_offset_end 396\n",
      "parts: abs_sent_offset [397, 402, 411, 415, 420, 430, 433, 441, 446, 452, 455, 458, 461, 465, 468, 471, 475, 483, 493, 498, 499, 511, 516, 517, 519, 523, 529, 535, 541, 543, 552, 554, 562, 564, 569, 570, 574, 578, 583, 588, 589, 601, 608, 609, 611, 616, 625, 627, 629, 633, 637, 639, 642, 652, 654, 657]\n",
      "abs_sent_offset 397\n",
      "abs_sent_offset_end 658\n",
      "parts: abs_sent_offset [0, 11, 20, 24, 31, 36, 42, 47, 51, 60, 63, 68]\n",
      "abs_sent_offset 0\n",
      "abs_sent_offset_end 69\n"
     ]
    }
   ],
   "source": [
    "# Parse the document and save into the sqlite server\n",
    "# see the intro-turtorial 1\n",
    "\n",
    "# Configure a doc pre-processer\n",
    "from snorkel.parser import TextDocPreprocessor\n",
    "doc_preprocessor = TextDocPreprocessor(path = 'data/samples', encoding = \"utf-8\")\n",
    "print doc_preprocessor.path\n",
    "\n",
    "corpus_parser.apply(doc_preprocessor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Check if the document has beed loaded\n",
    "from snorkel.models import Document, Sentence\n",
    "for doc in session.query(Document).all():\n",
    "    print doc.id\n",
    "    #print doc.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Candidate Type\n",
    "from snorkel.models import candidate_subclass, Document, Candidate\n",
    "rel_contract = candidate_subclass('Contractor-Contractee', ['org1', 'org2'])\n",
    "\n",
    "# Write the candidate extractor\n",
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import OrganizationMatcher\n",
    "ngrams         = Ngrams(n_max=7)\n",
    "org_matcher = OrganizationMatcher()\n",
    "cand_extractor = CandidateExtractor(rel_contract, [ngrams, ngrams], [org_matcher, org_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, dev and test \n",
    "from snorkel.models import Document\n",
    "\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents   = set()\n",
    "test_sents  = set()\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if i % 3 == 1:\n",
    "            dev_sents.add(s)\n",
    "        elif i % 3 == 2:\n",
    "            test_sents.add(s)\n",
    "        else:\n",
    "            train_sents.add(s)\n",
    "            \n",
    "print len(train_sents)\n",
    "print len(test_sents)\n",
    "print len(dev_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 2)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 2)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 1)\n"
     ]
    }
   ],
   "source": [
    "# Apply candidate extractors on all the sentences\n",
    "# Save the candidates into the databse\n",
    "# The rel_candidates will be splitted into train, dev, test \n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    cand_extractor.apply(sents, split=i)\n",
    "    print(\"Number of candidates:\", session.query(rel_contract).filter(rel_contract.split == i).count())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the labeling functions\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "def LF_between_and(c):\n",
    "    #print get_left_tokens(c[0], window=2)\n",
    "    if \"between\" in get_left_tokens(c[0], window=5):\n",
    "        #print get_between_tokens(c)\n",
    "        if \"and\" in get_between_tokens(c):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def LF_agreement(c):\n",
    "    if \"agreement\" in get_left_tokens(c[0], window=30):\n",
    "        return 1\n",
    "    return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number labeled:', 2)\n",
      "Sentence(Document b5dfde83-dde0-4235-b749-4c2aaf8abd06,2,THIS PURCHASE AND SALE AGREEMENT is entered into this  23rd, March,  2000, by and between Google Inc (hereinafter Buyer), 1545 Charleston Rd, Mountain View, CA 94043, and Cisco Systems, Inc. (hereinafter Company), 3571 N 1st St, San Jose, CA 95134, USA, and here is it.)\n",
      "\n",
      "Sentence(Document b5dfde83-dde0-4235-b749-4c2aaf8abd06,1,This Independent Contractor Agreement (\"Agreement\") is made and entered into by and between, Cisco System (\"Contractor\") and Microsoft Corp (“Client”).)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the first labeling function: LF_between_and\n",
    "labeled = []\n",
    "for c in session.query(rel_contract).filter(rel_contract.split == 0).all():\n",
    "    if LF_between_and(c) != 0:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))\n",
    "for i in range(len(labeled)):\n",
    "    print labeled[i].get_parent()\n",
    "    #print labeled[i].labels\n",
    "    print\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number labeled:', 2)\n",
      "Sentence(Document b5dfde83-dde0-4235-b749-4c2aaf8abd06,2,THIS PURCHASE AND SALE AGREEMENT is entered into this  23rd, March,  2000, by and between Google Inc (hereinafter Buyer), 1545 Charleston Rd, Mountain View, CA 94043, and Cisco Systems, Inc. (hereinafter Company), 3571 N 1st St, San Jose, CA 95134, USA, and here is it.)\n",
      "Contractor-Contractee(Span(\"Google Inc\", sentence=6, chars=[90,99], words=[18,19]), Span(\"Cisco Systems, Inc.\", sentence=6, chars=[171,189], words=[36,39]))\n",
      "\n",
      "Sentence(Document b5dfde83-dde0-4235-b749-4c2aaf8abd06,1,This Independent Contractor Agreement (\"Agreement\") is made and entered into by and between, Cisco System (\"Contractor\") and Microsoft Corp (“Client”).)\n",
      "Contractor-Contractee(Span(\"Cisco System\", sentence=5, chars=[93,104], words=[18,19]), Span(\"Microsoft Corp\", sentence=5, chars=[125,138], words=[26,27]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the second labeling function: LF_agreement\n",
    "labeled = []\n",
    "for c in session.query(rel_contract).filter(rel_contract.split == 0).all():\n",
    "    if LF_agreement(c) != 0:\n",
    "        labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))\n",
    "for i in range(len(labeled)):\n",
    "    print labeled[i].get_parent()\n",
    "    print labeled[i]\n",
    "    print\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Sentence(Document b5dfde83-dde0-4235-b749-4c2aaf8abd06,2,THIS PURCHASE AND SALE AGREEMENT is entered into this  23rd, March,  2000, by and between Google Inc (hereinafter Buyer), 1545 Charleston Rd, Mountain View, CA 94043, and Cisco Systems, Inc. (hereinafter Company), 3571 N 1st St, San Jose, CA 95134, USA, and here is it.)\n",
      "Google Inc   Cisco Systems, Inc.\n",
      "[Label (LF_between_and = 1), Label (LF_agreement = 1)]\n",
      "\n",
      "Sentence(Document b5dfde83-dde0-4235-b749-4c2aaf8abd06,1,This Independent Contractor Agreement (\"Agreement\") is made and entered into by and between, Cisco System (\"Contractor\") and Microsoft Corp (“Client”).)\n",
      "Cisco System   Microsoft Corp\n",
      "[Label (LF_between_and = 1), Label (LF_agreement = 1)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-802e0f545a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print L_train.get_candidate(session, i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mL_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mL_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mL_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kunling/Dropbox/decisionengines/snorkel/snorkel/annotations.pyc\u001b[0m in \u001b[0;36mget_candidate\u001b[0;34m(self, session, i)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m\"\"\"Return the Candidate object corresponding to row i\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_row_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "LFs = [LF_between_and, LF_agreement]\n",
    "\n",
    "# Apply the labelling functions\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "import numpy as np\n",
    "labeler = LabelAnnotator(lfs=LFs)\n",
    "\n",
    "np.random.seed(1701)\n",
    "L_train = labeler.apply(split=0)\n",
    "# L_train is essentially the sparse matrix\n",
    "# check the labeling results\n",
    "\n",
    "for i in range(3):\n",
    "    #print L_train.get_candidate(session, i)\n",
    "    print L_train.get_candidate(session, i).get_parent()\n",
    "    print L_train.get_candidate(session, i).org1.get_span(), \" \", L_train.get_candidate(session, i).org2.get_span() \n",
    "    print L_train.get_candidate(session, i).labels\n",
    "    print \n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching BRAT server at http://localhost:8001 [pid=92760]...\n",
      "Killing BRAT server [92693]...\n",
      "Removed existing collection at 'contract/train'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='http://localhost:8001/index.xhtml#/contract/train/' target='_blank'>Launch BRAT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch Brat\n",
    "from snorkel.contrib.brat import BratAnnotator\n",
    "\n",
    "brat = BratAnnotator(session, rel_contract, encoding='utf-8', annotator_name='brat')\n",
    "\n",
    "# Initilize the brat program\n",
    "# the brat would copy the training data (split = 0) frrom the sqlite server \n",
    "# to the folder \"snorkel/snorkel/snorkel/contrib/brat/brat-v1.3_Crunchy_Frog/data/contract/train\"\n",
    "brat.init_collection(\"contract/train\", split=0, overwrite=True)\n",
    "\n",
    "brat.view(\"contract/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contractor-Contractee(Span(\"Google Inc\", sentence=6, chars=[90,99], words=[18,19]), Span(\"Cisco Systems, Inc.\", sentence=6, chars=[171,189], words=[36,39]))\n",
      "Google Inc   Cisco Systems, Inc.\n",
      "[Label (LF_between_and = 1), Label (LF_agreement = 1)]\n",
      "-------------\n",
      "Contractor-Contractee(Span(\"Cisco System\", sentence=5, chars=[93,104], words=[18,19]), Span(\"Microsoft Corp\", sentence=5, chars=[125,138], words=[26,27]))\n",
      "Cisco System   Microsoft Corp\n",
      "[Label (LF_between_and = 1), Label (LF_agreement = 1)]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#load all the candidates and labeling results from the server\n",
    "# the candiates are labeled \n",
    "train_cands = session.query(rel_contract).filter(rel_contract.split == 0).order_by(rel_contract.id).all()\n",
    "for c in train_cands:\n",
    "    print c\n",
    "    print c.org1.get_span(), \" \", c.org2.get_span()\n",
    "    print c.labels\n",
    "    print '-------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document b5dfde83-dde0-4235-b749-4c2aaf8abd06, Document b745346e-16a3-46ba-8adc-92b1fa085c38, Document c5dbaa73-8076-4385-944c-1539a30152d7]\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "documents = session.query(Document).all()\n",
    "print documents\n",
    "for doc in documents:\n",
    "    #print doc.sentences\n",
    "    print doc.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents\n",
      "{u'b5dfde83-dde0-4235-b749-4c2aaf8abd06': Document b5dfde83-dde0-4235-b749-4c2aaf8abd06}\n",
      "\n",
      "annotations\n",
      "{'b5dfde83-dde0-4235-b749-4c2aaf8abd06': {u'R1': (u'Contractor-Contractee', u'T1', u'T2'), u'R2': (u'Contractor-Contractee', u'T3', u'T4'), u'T4': {'mention': u'Cisco Systems, Inc.', 'abs_char_start': 510, 'abs_char_end': 529, 'entity_type': u'Org'}, u'T2': {'mention': u'Microsoft Corp', 'abs_char_start': 313, 'abs_char_end': 327, 'entity_type': u'Org'}, u'T3': {'mention': u'Google Inc', 'abs_char_start': 429, 'abs_char_end': 439, 'entity_type': u'Org'}, u'T1': {'mention': u'Cisco System', 'abs_char_start': 281, 'abs_char_end': 293, 'entity_type': u'Org'}}}\n",
      "document: Document b5dfde83-dde0-4235-b749-4c2aaf8abd06\n",
      "annottions: {u'R1': (u'Contractor-Contractee', u'T1', u'T2'), u'R2': (u'Contractor-Contractee', u'T3', u'T4'), u'T4': {'mention': u'Cisco Systems, Inc.', 'abs_char_start': 510, 'abs_char_end': 529, 'entity_type': u'Org'}, u'T2': {'mention': u'Microsoft Corp', 'abs_char_start': 313, 'abs_char_end': 327, 'entity_type': u'Org'}, u'T3': {'mention': u'Google Inc', 'abs_char_start': 429, 'abs_char_end': 439, 'entity_type': u'Org'}, u'T1': {'mention': u'Cisco System', 'abs_char_start': 281, 'abs_char_end': 293, 'entity_type': u'Org'}}\n",
      "abs_char_start: 510\n",
      "abs_char_end: 529\n",
      "sent abs char offset: [0, 188, 339]\n",
      "sent_id 2\n",
      "char_start: 171\n",
      "char_end: 190\n",
      "abs_char_start: 313\n",
      "abs_char_end: 327\n",
      "sent abs char offset: [0, 188, 339]\n",
      "sent_id 1\n",
      "char_start: 125\n",
      "char_end: 139\n",
      "abs_char_start: 429\n",
      "abs_char_end: 439\n",
      "sent abs char offset: [0, 188, 339]\n",
      "sent_id 2\n",
      "char_start: 90\n",
      "char_end: 100\n",
      "abs_char_start: 281\n",
      "abs_char_end: 293\n",
      "sent abs char offset: [0, 188, 339]\n",
      "sent_id 1\n",
      "char_start: 93\n",
      "char_end: 105\n",
      "spans\n",
      "{u'T4': TemporarySpan(\"Cisco Systems, Inc.\", sentence=6, chars=[171,189], words=[36,39]), u'T2': TemporarySpan(\"Microsoft Corp\", sentence=5, chars=[125,138], words=[26,27]), u'T3': TemporarySpan(\"Google Inc\", sentence=6, chars=[90,99], words=[18,19]), u'T1': TemporarySpan(\"Cisco System\", sentence=5, chars=[93,104], words=[18,19])}\n",
      "relations:\n",
      "{u'R1': [TemporarySpan(\"Cisco System\", sentence=5, chars=[93,104], words=[18,19]), TemporarySpan(\"Microsoft Corp\", sentence=5, chars=[125,138], words=[26,27])], u'R2': [TemporarySpan(\"Google Inc\", sentence=6, chars=[90,99], words=[18,19]), TemporarySpan(\"Cisco Systems, Inc.\", sentence=6, chars=[171,189], words=[36,39])]}\n",
      "\n",
      "<2x1 sparse matrix of type '<type 'numpy.int64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>\n",
      "  (0, 0)\t1\n",
      "  (1, 0)\t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapped 2/2 (100%) of BRAT labels to candidates\n"
     ]
    }
   ],
   "source": [
    "# import the gold labels from the brat files \n",
    "# match the relationship stored in the brat folder \"contract/train\" \n",
    "# with the training candidates in the current databse\n",
    "# Note that the candidates exsit in \"contract/train\" but not exisit in the \"train_cands\"\n",
    "# will not be imported to the databse\n",
    "# \n",
    "\n",
    "brat.import_gold_labels(session, \"contract/train\", train_cands)\n",
    "\n",
    "\n",
    "# Now we can load the brat_labels from the current database(session)\n",
    "# Note that the annotator_name='brat' becasue when we we initilize the BratAnnotator\n",
    "# the default annotator name will be 'brat'\n",
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_train = load_gold_labels(session, annotator_name='brat', split=0)\n",
    "print repr(L_gold_train)\n",
    "print L_gold_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "# Fit the generative model\n",
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=1000, decay=0.95, step_size=0.01 / L_train.shape[0], reg_param=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 1.0\n",
      "Neg. class accuracy: 0.0\n",
      "Precision            1.0\n",
      "Recall               1.0\n",
      "F1                   1.0\n",
      "----------------------------------------\n",
      "TP: 2 | FP: 0 | TN: 0 | FN: 0\n",
      "========================================\n",
      "\n",
      "[ 0.98911205  0.98911205]\n"
     ]
    }
   ],
   "source": [
    "# error analysis of the generative model\n",
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_train, L_gold_train)\n",
    "\n",
    "# generate the noisy-aware lables (marginals) for the training data\n",
    "train_marginals = gen_model.marginals(L_train)\n",
    "print train_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.907386</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>0.908340</td>\n",
       "      <td>0.698566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895701</td>\n",
       "      <td>0.7699</td>\n",
       "      <td>0.891178</td>\n",
       "      <td>0.691393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.907386    0.7731   0.908340  0.698566\n",
       "1  0.895701    0.7699   0.891178  0.691393"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the coverage of the generative model for the LFs\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error! Collection at 'contract/dev' already exists. Please set overwrite=True to erase all existing annotations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='http://localhost:8001/index.xhtml#/contract/dev/' target='_blank'>Launch BRAT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label dev data using brat\n",
    "brat.init_collection(\"contract/dev\", split=1, overwrite=False)\n",
    "brat.view(\"contract/dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents\n",
      "{u'b745346e-16a3-46ba-8adc-92b1fa085c38': Document b745346e-16a3-46ba-8adc-92b1fa085c38}\n",
      "\n",
      "annotations\n",
      "{'b745346e-16a3-46ba-8adc-92b1fa085c38': {u'R1': (u'Contractor-Contractee', u'T1', u'T2'), u'R2': (u'Contractor-Contractee', u'T3', u'T4'), u'T4': {'mention': u'The Hive Inc.', 'abs_char_start': 575, 'abs_char_end': 588, 'entity_type': u'Org'}, u'T2': {'mention': u'Cisco Systems, Inc.', 'abs_char_start': 187, 'abs_char_end': 206, 'entity_type': u'Org'}, u'T3': {'mention': u'Starbucks Corp', 'abs_char_start': 484, 'abs_char_end': 498, 'entity_type': u'Org'}, u'T1': {'mention': u'Microsoft Corporation', 'abs_char_start': 88, 'abs_char_end': 109, 'entity_type': u'Org'}}}\n",
      "document: Document b745346e-16a3-46ba-8adc-92b1fa085c38\n",
      "annottions: {u'R1': (u'Contractor-Contractee', u'T1', u'T2'), u'R2': (u'Contractor-Contractee', u'T3', u'T4'), u'T4': {'mention': u'The Hive Inc.', 'abs_char_start': 575, 'abs_char_end': 588, 'entity_type': u'Org'}, u'T2': {'mention': u'Cisco Systems, Inc.', 'abs_char_start': 187, 'abs_char_end': 206, 'entity_type': u'Org'}, u'T3': {'mention': u'Starbucks Corp', 'abs_char_start': 484, 'abs_char_end': 498, 'entity_type': u'Org'}, u'T1': {'mention': u'Microsoft Corporation', 'abs_char_start': 88, 'abs_char_end': 109, 'entity_type': u'Org'}}\n",
      "abs_char_start: 575\n",
      "abs_char_end: 588\n",
      "sent abs char offset: [0, 295, 373, 397]\n",
      "sent_id 3\n",
      "char_start: 178\n",
      "char_end: 191\n",
      "abs_char_start: 187\n",
      "abs_char_end: 206\n",
      "sent abs char offset: [0, 295, 373, 397]\n",
      "sent_id 0\n",
      "char_start: 187\n",
      "char_end: 206\n",
      "abs_char_start: 484\n",
      "abs_char_end: 498\n",
      "sent abs char offset: [0, 295, 373, 397]\n",
      "sent_id 3\n",
      "char_start: 87\n",
      "char_end: 101\n",
      "abs_char_start: 88\n",
      "abs_char_end: 109\n",
      "sent abs char offset: [0, 295, 373, 397]\n",
      "sent_id 0\n",
      "char_start: 88\n",
      "char_end: 109\n",
      "spans\n",
      "{u'T4': TemporarySpan(\"he Hive Inc. \", sentence=10, chars=[178,190], words=[36,38]), u'T2': TemporarySpan(\"Cisco Systems, Inc.\", sentence=7, chars=[187,205], words=[36,39]), u'T3': TemporarySpan(\"tarbucks Corp \", sentence=10, chars=[87,100], words=[17,18]), u'T1': TemporarySpan(\"Microsoft Corporation\", sentence=7, chars=[88,108], words=[17,18])}\n",
      "relations:\n",
      "{u'R1': [TemporarySpan(\"Microsoft Corporation\", sentence=7, chars=[88,108], words=[17,18]), TemporarySpan(\"Cisco Systems, Inc.\", sentence=7, chars=[187,205], words=[36,39])], u'R2': [TemporarySpan(\"tarbucks Corp \", sentence=10, chars=[87,100], words=[17,18]), TemporarySpan(\"he Hive Inc. \", sentence=10, chars=[178,190], words=[36,38])]}\n",
      "\n",
      "  (0, 0)\t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: b745346e-16a3-46ba-8adc-92b1fa085c38 Span annotations do not match BRAT:[The Hive Inc.]!=SNORKEL:[he Hive Inc. ] [575:588]\n",
      "Warning: b745346e-16a3-46ba-8adc-92b1fa085c38 Span annotations do not match BRAT:[Starbucks Corp]!=SNORKEL:[tarbucks Corp ] [484:498]\n",
      "Mapped 1/2 (50%) of BRAT labels to candidates\n"
     ]
    }
   ],
   "source": [
    "# load up the gold labels for dev data\n",
    "dev_cands = session.query(rel_contract).filter(rel_contract.split == 1).order_by(rel_contract.id).all()\n",
    "brat.import_gold_labels(session, \"contract/dev\", dev_cands)\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='brat', split=1)\n",
    "print L_gold_dev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[reRNN] Training model\n",
      "[reRNN] n_train=2  #epochs=20  batch size=2\n",
      "[reRNN] Epoch 0 (0.20s)\tAverage loss=0.695944\tDev F1=66.67\n",
      "[reRNN] Epoch 1 (0.36s)\tAverage loss=0.560884\tDev F1=66.67\n",
      "[reRNN] Epoch 2 (0.51s)\tAverage loss=0.303893\tDev F1=66.67\n",
      "[reRNN] Epoch 3 (0.64s)\tAverage loss=0.113205\tDev F1=66.67\n",
      "[reRNN] Epoch 4 (0.77s)\tAverage loss=0.070595\tDev F1=66.67\n",
      "[reRNN] Epoch 5 (0.89s)\tAverage loss=0.060619\tDev F1=66.67\n",
      "[reRNN] Epoch 6 (1.02s)\tAverage loss=0.060886\tDev F1=66.67\n",
      "[reRNN] Epoch 7 (1.15s)\tAverage loss=0.064195\tDev F1=66.67\n",
      "[reRNN] Epoch 8 (1.29s)\tAverage loss=0.067799\tDev F1=66.67\n",
      "[reRNN] Epoch 9 (1.42s)\tAverage loss=0.070830\tDev F1=66.67\n",
      "[reRNN] Epoch 10 (1.54s)\tAverage loss=0.073072\tDev F1=66.67\n",
      "[reRNN] Epoch 11 (1.67s)\tAverage loss=0.074511\tDev F1=66.67\n",
      "[reRNN] Epoch 12 (1.80s)\tAverage loss=0.075199\tDev F1=66.67\n",
      "[reRNN] Epoch 13 (1.92s)\tAverage loss=0.075198\tDev F1=66.67\n",
      "[reRNN] Epoch 14 (2.05s)\tAverage loss=0.074575\tDev F1=66.67\n",
      "[reRNN] Epoch 15 (2.17s)\tAverage loss=0.073414\tDev F1=66.67\n",
      "[reRNN] Epoch 16 (2.30s)\tAverage loss=0.071851\tDev F1=66.67\n",
      "[reRNN] Model saved as <reRNN>\n",
      "[reRNN] Epoch 17 (3.97s)\tAverage loss=0.070060\tDev F1=66.67\n",
      "[reRNN] Epoch 18 (4.11s)\tAverage loss=0.068174\tDev F1=66.67\n",
      "[reRNN] Epoch 19 (4.23s)\tAverage loss=0.066287\tDev F1=66.67\n",
      "[reRNN] Training done (4.25s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/reRNN/reRNN-16\n",
      "[reRNN] Loaded model <reRNN>\n"
     ]
    }
   ],
   "source": [
    "# Training an LSTM model\n",
    "# Carefule that the no. of relationships in dev dataset must >=2\n",
    "from snorkel.learning.disc_models.rnn import reRNN\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.01,\n",
    "    'dim':        50,\n",
    "    'n_epochs':   20,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1,\n",
    "    'max_sentence_length': 100\n",
    "}\n",
    "\n",
    "lstm = reRNN(seed=1701, n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.500, Recall: 1.000, F1 Score: 0.667\n"
     ]
    }
   ],
   "source": [
    "# The accuracy of the lstm for the dev data\n",
    "p, r, f1 = lstm.score(dev_cands, L_gold_dev)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Sentence(Document b745346e-16a3-46ba-8adc-92b1fa085c38,0,THIS PURCHASE AND SALE AGREEMENT is entered into this  23rd Feb,  2017,  by and between Microsoft Corporation (hereinafter Buyer), 600 North Wolfe Street, Baltimore, Maryland, 21287, and Cisco Systems, Inc. (hereinafter Company), 3700 Momentum St, San Jose, CA 95134-2206, USA, and here is it.)\n",
      "Microsoft Corporation   Cisco Systems, Inc.\n",
      "[Label (LF_between_and = 1), Label (LF_agreement = 1)]\n",
      "0.989112051215\n",
      "0.998094\n",
      "\n",
      "Sentence(Document b745346e-16a3-46ba-8adc-92b1fa085c38,3,THIS PURCHASE AND SALE AGREEMENT is entered into this  11 Feb,  2020,  by and between Starbucks Corp (hereinafter Buyer), 600 North Wolfe Street, Baltimore, Maryland, 21287,and The Hive Inc. (hereinafter Company), 3700 Momentum St, San Jose, CA 95134-2206, USA.)\n",
      "Starbucks Corp   Hive Inc.\n",
      "[Label (LF_between_and = 1), Label (LF_agreement = 1)]\n",
      "0.989112051215\n",
      "0.998075\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2bd0eaa8d311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlstm_dev_marginals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarginals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_cands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mL_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mL_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mL_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;31m# labels by LFs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kunling/Dropbox/decisionengines/snorkel/snorkel/annotations.pyc\u001b[0m in \u001b[0;36mget_candidate\u001b[0;34m(self, session, i)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;34m\"\"\"Return the Candidate object corresponding to row i\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_row_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)\n",
    "dev_marginals = gen_model.marginals(L_dev) \n",
    "lstm_dev_marginals = lstm.marginals(dev_cands)\n",
    "for i in range(8):\n",
    "    print L_dev.get_candidate(session, i).get_parent() # sentence\n",
    "    print L_dev.get_candidate(session, i).org1.get_span(), \" \", L_dev.get_candidate(session, i).org2.get_span() # candidate\n",
    "    print L_dev.get_candidate(session, i).labels # labels by LFs\n",
    "    print dev_marginals[i] # labels by generative models\n",
    "    print lstm_dev_marginals[i]\n",
    "    print \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finish the labeling of  test data\n",
    "brat.init_collection(\"contract/test\", split=2, overwrite=False)\n",
    "brat.view(\"contract/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Contractor-Contractee(Span(\"SmartPhone Services\", sentence=10, chars=[0,18], words=[0,1]), Span(\"Darshi Inc.\", sentence=10, chars=[24,34], words=[3,4]))]\n",
      "  (0, 0)\t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapped 1/1 (100%) of BRAT labels to candidates\n"
     ]
    }
   ],
   "source": [
    "# load up the gold labels for test data\n",
    "test_cands = session.query(rel_contract).filter(rel_contract.split == 2).order_by(rel_contract.id).all()\n",
    "print test_cands\n",
    "brat.import_gold_labels(session, \"contract/test\", test_cands)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='brat', split=2)\n",
    "print L_gold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Sentence(Document c5dbaa73-8076-4385-944c-1539a30152d7,0,SmartPhone Services and Darshi Inc. agree that the contract is valid.)\n",
      "Contractor-Contractee(Span(\"SmartPhone Services\", sentence=10, chars=[0,18], words=[0,1]), Span(\"Darshi Inc.\", sentence=10, chars=[24,34], words=[3,4]))\n",
      "Starbucks Corp   CA 95134-2206\n",
      "[]\n",
      "0.5\n",
      "0.99784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_test = labeler.apply_existing(split=2)\n",
    "# output marginals of the generative model\n",
    "# It should be noted that the generative model depends on\n",
    "# the LFs and operates on the output of labeler\n",
    "\n",
    "test_marginals = gen_model.marginals(L_test) \n",
    "lstm_test_marginals = lstm.marginals(dev_cands)\n",
    "for i in range(1):\n",
    "    print L_test.get_candidate(session, i).get_parent() # sentence\n",
    "    print L_test.get_candidate(session, i) # candidate\n",
    "    print L_dev.get_candidate(session, i).org1.get_span(), \" \", L_dev.get_candidate(session, i).org2.get_span() # candidate\n",
    "    print L_test.get_candidate(session, i).labels # labels by LFs\n",
    "    print test_marginals[i] # labels by generative models\n",
    "    print lstm_test_marginals[i]\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlalchemy.engine.base.Connection object at 0x1221c5210>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
